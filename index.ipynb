{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge of Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will: \n",
    "\n",
    "- Use Lasso and Ridge regression with scikit-learn \n",
    "- Compare and contrast Lasso, Ridge and non-regularized regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at `.info()` of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, split the data into `X` (predictor) and `y` (target) variables \n",
    "- Split the data into 75-25 training-test sets. Set the `random_state` to 10 \n",
    "- Remove all columns of `object` type from `X_train` and `X_test` and assign them to `X_train_cont` and `X_test_cont`, respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns=['SalePrice'], axis=1)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.25, random_state=22)\n",
    "\n",
    "# Remove \"object\"-type features from X\n",
    "cont_features = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
    "\n",
    "# Remove \"object\"-type features from X_train and X_test\n",
    "X_train_cont = X_train.loc[:,cont_features]\n",
    "X_test_cont = X_test.loc[:,cont_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to build a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill the missing values in data using median of the columns (use [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)) \n",
    "- Fit a linear regression model to this data \n",
    "- Compute the R-squared and the MSE for both the training and test sets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8025192127123502\n",
      "Test r^2: 0.8332358140362535\n",
      "Training MSE: 1211656890.909874\n",
      "Test MSE: 1135124796.7988367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with median using SimpleImputer\n",
    "impute = SimpleImputer(strategy='median')\n",
    "X_train_imputed = impute.fit_transform(X_train_cont)\n",
    "X_test_imputed = impute.transform(X_test_cont)\n",
    "\n",
    "# Fit the model and print R2 and MSE for training and test sets\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Print R2 and MSE for training and test sets\n",
    "print('Training r^2:', linreg.score(X_train_imputed, y_train))\n",
    "print('Test r^2:', linreg.score(X_test_imputed, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train_imputed)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg.predict(X_test_imputed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize your data using a `StandardScalar`  \n",
    "- Fit a linear regression model to this data \n",
    "- Compute the R-squared and the MSE for both the training and test sets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2 Scaled: 0.8025330594197979\n",
      "Test r^2 Sclaed: 0.8332831321334606\n",
      "Training MSE Scaled: 1211571933.4883146\n",
      "Test MSE Scaled: 1134802713.5819478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the train and test data\n",
    "ss = StandardScaler()\n",
    "X_train_imputed_scaled = ss.fit_transform(X_train_imputed)\n",
    "X_test_imputed_scaled = ss.transform(X_test_imputed)\n",
    "\n",
    "# Fit the model\n",
    "linreg_norm = LinearRegression()\n",
    "linreg_norm.fit(X_train_imputed_scaled, y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE for training and test sets\n",
    "print('Training r^2 Scaled:', linreg_norm.score(X_train_imputed_scaled, y_train))\n",
    "print('Test r^2 Sclaed:', linreg_norm.score(X_test_imputed_scaled, y_test))\n",
    "print('Training MSE Scaled:', mean_squared_error(y_train, linreg_norm.predict(X_train_imputed_scaled)))\n",
    "print('Test MSE Scaled:', mean_squared_error(y_test, linreg_norm.predict(X_test_imputed_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above models didn't include categorical variables so far, let's include them! \n",
    "\n",
    "\n",
    "- Include all columns of `object` type from `X_train` and `X_test` and assign them to `X_train_cat` and `X_test_cat`, respectively \n",
    "- Fill missing values in all these columns with the string `'missing'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "features_cat = [col for col in X.columns if X[col].dtype in [np.object]]\n",
    "X_train_cat = X_train.loc[:, features_cat]\n",
    "X_test_cat = X_test.loc[:, features_cat]\n",
    "\n",
    "# Fill missing values with the string 'missing'\n",
    "X_train_cat.fillna(value='missing', inplace=True)\n",
    "X_test_cat.fillna(value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create X_cat which contains only the categorical variables\n",
    "# features_cat = [col for col in X.columns if X[col].dtype in [np.object]]\n",
    "# X_train_cat = X_train.loc[:, features_cat]\n",
    "# X_test_cat = X_test.loc[:, features_cat]\n",
    "\n",
    "# # Fill missing values with the string 'missing'\n",
    "# X_train_cat.fillna(value=\"missing\", inplace=True)\n",
    "# X_test_cat.fillna(value=\"missing\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-hot encode all these categorical columns using `OneHotEncoder` \n",
    "- Transform the training and test DataFrames (`X_train_cat`) and (`X_test_cat`) \n",
    "- Run the given code to convert these transformed features into DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 43)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>571</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1356</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>RM</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>OldTown</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>986</td>\n",
       "      <td>RM</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>OldTown</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Fa</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>356</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091</td>\n",
       "      <td>960</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>812</td>\n",
       "      <td>C (all)</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>IDOTRR</td>\n",
       "      <td>...</td>\n",
       "      <td>Basment</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>N</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Alloca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1093</td>\n",
       "      <td>132</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1094</td>\n",
       "      <td>885</td>\n",
       "      <td>FV</td>\n",
       "      <td>Pave</td>\n",
       "      <td>missing</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Somerst</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>CWD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index MSZoning Street    Alley LotShape LandContour Utilities LotConfig  \\\n",
       "0       571       RL   Pave  missing      Reg         Lvl    AllPub    Inside   \n",
       "1      1356       RL   Pave  missing      Reg         Lvl    AllPub    Corner   \n",
       "2       198       RM   Pave  missing      Reg         Lvl    AllPub    Corner   \n",
       "3       230       RL   Pave  missing      Reg         Lvl    AllPub    Inside   \n",
       "4       986       RM   Pave  missing      Reg         Lvl    AllPub    Corner   \n",
       "...     ...      ...    ...      ...      ...         ...       ...       ...   \n",
       "1090    356       RL   Pave  missing      IR1         Lvl    AllPub    Inside   \n",
       "1091    960       RL   Pave  missing      IR1         Lvl    AllPub    Inside   \n",
       "1092    812  C (all)   Grvl  missing      Reg         Bnk    AllPub    Inside   \n",
       "1093    132       RL   Pave  missing      Reg         Lvl    AllPub    Corner   \n",
       "1094    885       FV   Pave  missing      IR1         Lvl    AllPub   CulDSac   \n",
       "\n",
       "     LandSlope Neighborhood  ... GarageType GarageFinish GarageQual  \\\n",
       "0          Gtl        NAmes  ...     Attchd          Unf         TA   \n",
       "1          Gtl        NAmes  ...     Attchd          RFn         TA   \n",
       "2          Gtl      OldTown  ...    missing      missing    missing   \n",
       "3          Gtl        NAmes  ...     Attchd          RFn         TA   \n",
       "4          Gtl      OldTown  ...     Attchd          Unf         Fa   \n",
       "...        ...          ...  ...        ...          ...        ...   \n",
       "1090       Gtl      Gilbert  ...     Attchd          RFn         TA   \n",
       "1091       Gtl      BrkSide  ...    missing      missing    missing   \n",
       "1092       Mod       IDOTRR  ...    Basment          Unf         TA   \n",
       "1093       Gtl        NAmes  ...     Detchd          Unf         TA   \n",
       "1094       Gtl      Somerst  ...     Attchd          Fin         TA   \n",
       "\n",
       "     GarageCond PavedDrive   PoolQC    Fence MiscFeature SaleType  \\\n",
       "0            TA          Y  missing  missing     missing       WD   \n",
       "1            TA          Y  missing     GdWo     missing       WD   \n",
       "2       missing          Y  missing    MnPrv     missing       WD   \n",
       "3            TA          Y  missing  missing     missing       WD   \n",
       "4            TA          Y  missing  missing     missing       WD   \n",
       "...         ...        ...      ...      ...         ...      ...   \n",
       "1090         TA          Y  missing  missing     missing       WD   \n",
       "1091    missing          Y  missing  missing     missing       WD   \n",
       "1092         TA          N  missing  missing        Shed       WD   \n",
       "1093         TA          Y  missing  missing     missing       WD   \n",
       "1094         TA          Y  missing  missing     missing      CWD   \n",
       "\n",
       "     SaleCondition  \n",
       "0          Abnorml  \n",
       "1           Normal  \n",
       "2          Abnorml  \n",
       "3           Normal  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1090        Normal  \n",
       "1091        Normal  \n",
       "1092        Alloca  \n",
       "1093        Normal  \n",
       "1094       Abnorml  \n",
       "\n",
       "[1095 rows x 44 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Metal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Metal'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-d4a83f8f57ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Metal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3735\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3737\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Metal'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# X_test_cat.loc['Metal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncode categorical variables\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Transform training and test sets\n",
    "X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "# Convert these columns into a DataFrame \n",
    "columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "cat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\n",
    "cat_test_df = pd.DataFrame(X_test_ohe.todense(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # OneHotEncode categorical variables\n",
    "# ohe = OneHotEncoder(##### this is what was different)\n",
    "\n",
    "# # Transform training and test sets\n",
    "# X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "# X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "# # Convert these columns into a DataFrame\n",
    "# columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "# cat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\n",
    "# cat_test_df = pd.DataFrame(X_test_ohe, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine `X_train_imputed_scaled` and `cat_train_df` into a single DataFrame  \n",
    "- Similarly, combine `X_test_imputed_scaled` and `cat_test_df` into a single DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_train_all = pd.concat([pd.DataFrame(X_train_imputed_scaled), cat_train_df], axis=1)\n",
    "X_test_all = pd.concat([pd.DataFrame(X_test_imputed_scaled), cat_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a linear regression model using all the features (`X_train_all`). Also, print the R-squared and the MSE for both the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.9231809925987229\n",
      "Test r^2: -6.404322779485125e+21\n",
      "Training MSE: 471328279.3178082\n",
      "Test MSE: 4.359272676974901e+31\n"
     ]
    }
   ],
   "source": [
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r^2:', linreg_all.score(X_train_all, y_train))\n",
    "print('Test r^2:', linreg_all.score(X_test_all, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train_all)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9231809925987229\n",
      "MSE: 471328279.3178082\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train_all, y_train)\n",
    "\n",
    "print(f'R^2:', (linreg_all.score(X_train_all, y_train)))\n",
    "print(f'MSE:', (mean_squared_error(y_train, linreg_all.predict(X_train_all))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R-squared is very high, but the test R-squared is negative! Similarly, the scale of the test MSE is orders of magnitude higher than that of the training MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables, `X_train_all`) to build two models - one each for Lasso and Ridge regression. Each time, look at R-squared and MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.9462907001349429\n",
      "Training MSE Lasso alpha 1: 329537086.52502936\n",
      "Testing R^2: 0.8171005029171295\n",
      "Testing MSE Lasso alpha 1: 1244954084.4815245\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train_all, y_train)\n",
    "\n",
    "print(f'Training R^2:', lasso.score(X_train_all, y_train))\n",
    "print(f'Training MSE Lasso alpha 1:', mean_squared_error(y_train, lasso.predict(X_train_all)))\n",
    "print(f'Testing R^2:', lasso.score(X_test_all, y_test))\n",
    "print(f'Testing MSE Lasso alpha 1:', mean_squared_error(y_test, lasso.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.9448947184077532\n",
      "Training MSE Lasso alpha 10: 338102227.9879806\n",
      "Testing R^2: 0.8279560267382309\n",
      "Testing MSE Lasso alpha 10: 1171063073.648711\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "\n",
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(X_train_all, y_train)\n",
    "\n",
    "print(f'Training R^2:', lasso.score(X_train_all, y_train))\n",
    "print(f'Training MSE Lasso alpha 10:', mean_squared_error(y_train, lasso.predict(X_train_all)))\n",
    "print(f'Testing R^2:', lasso.score(X_test_all, y_test))\n",
    "print(f'Testing MSE Lasso alpha 10:', mean_squared_error(y_test, lasso.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.9272002702491937\n",
      "Training MSE Ridge alpha 1: 446667726.1138178\n",
      "Testing R^2: 0.8722571909886878\n",
      "Testing MSE Ridge alpha 1: 869515413.5373003\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train_all, y_train)\n",
    "\n",
    "print(f'Training R^2:', ridge.score(X_train_all, y_train))\n",
    "print(f'Training MSE Ridge alpha 1:', mean_squared_error(y_train, ridge.predict(X_train_all)))\n",
    "print(f'Testing R^2:', ridge.score(X_test_all, y_test))\n",
    "print(f'Testing MSE Ridge alpha 1:', mean_squared_error(y_test, ridge.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.8979200679292753\n",
      "Training MSE Ridge alpha 10: 626318412.1144156\n",
      "Testing R^2: 0.884899813576607\n",
      "Testing MSE Ridge alpha 10: 783460039.5181103\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train_all, y_train)\n",
    "\n",
    "print(f'Training R^2:', ridge.score(X_train_all, y_train))\n",
    "print(f'Training MSE Ridge alpha 10:', mean_squared_error(y_train, ridge.predict(X_train_all)))\n",
    "print(f'Testing R^2:', ridge.score(X_test_all, y_test))\n",
    "print(f'Testing MSE Ridge alpha 10:', mean_squared_error(y_test, ridge.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the metrics    \n",
    "\n",
    "Write your conclusions here: \n",
    "_________________________________\n",
    "\n",
    "r^2 Training: values are smaller on ridge, and smallest when alpha increases\n",
    "    * Training Lasso alpha 1 R^2: 0.9462907001349429\n",
    "    * Training Lasso alpha 10 R^2: 0.9448947184077532\n",
    "    * Training Ridge alpha 1 R^2: 0.9272002702491937\n",
    "    *  **Training Ridge alpha 10 R^2: 0.8979200679292753**\n",
    "    \n",
    "    \n",
    "MSE training: values are smaller on lasso, ans smallest when alpha increases\n",
    "    * Training MSE Lasso alpha 1: 329537086.52502936\n",
    "    *  **Training MSE Lasso alpha 10: 338102227.9879806**\n",
    "    * Training MSE Ridge alpha 1: 446667726.1138178\n",
    "    * Training MSE Ridge alpha 10: 626318412.1144156\n",
    "    \n",
    "r^2 Testing: values are smaller on lasso, and smallest when alpha decreases\n",
    "    *  **Testing Lasso alpha 1 R^2: 0.8171005029171295**\n",
    "    * Testing Lasso alpha 10  R^2: 0.8279560267382309\n",
    "    * Testing Ridge alpha 1 R^2: 0.8722571909886878\n",
    "    * Testing Ridge alpha 10 R^2: 0.884899813576607\n",
    "    \n",
    "MSE Testing: values are smllest on Ridge, and when alpha increases\n",
    "    * Testing MSE Lasso alpha 1: 1244954084.4815245\n",
    "    * Testing MSE Lasso alpha 10: 1171063073.648711\n",
    "    * Testing MSE Ridge alpha 1: 869515413.5373003\n",
    "    *  **Testing MSE Ridge alpha 10: 783460039.5181103**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso\n",
    "\n",
    "Use 10**(-10) as an estimate that is very close to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of Ridge params almost zero\n",
    "print(sum(abs(ridge.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "# Number of Lasso params almost zero\n",
    "print(sum(abs(lasso.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "0.21885521885521886\n"
     ]
    }
   ],
   "source": [
    "print(len(lasso.coef_))\n",
    "print(sum(abs(lasso.coef_) < 10**(-10))/ len(lasso.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To bring all of our work together lets take a moment to put all of our preprocessing steps for categorical and continuous variables into one function. This function should take in our features as a dataframe `X` and target as a Series `y` and return a training and test DataFrames with all of our preprocessed features along with training and test targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, y):\n",
    "    '''Takes in features and target and implements all preprocessing steps for categorical and continuous features returning \n",
    "    train and test DataFrames with targets'''\n",
    "    \n",
    "    # Train-test split (75-25), set seed to 10\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.25, random_state=10)\n",
    "    \n",
    "    # Remove \"object\"-type features and SalesPrice from X\n",
    "    cont_features = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
    "    X_train_cont = X_train.loc[:,cont_features]\n",
    "    X_test_cont = X_test.loc[:,cont_features]\n",
    "    \n",
    "\n",
    "    # Impute missing values with median using SimpleImputer\n",
    "    from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # Impute missing values with median using SimpleImputer\n",
    "    impute = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = impute.fit_transform(X_train_cont)\n",
    "    X_test_imputed = impute.transform(X_test_cont)\n",
    "\n",
    "    # Scale the train and test data\n",
    "    ss = StandardScaler()\n",
    "    X_train_imputed_scaled = ss.fit_transform(X_train_imputed)\n",
    "    X_test_imputed_scaled = ss.fit(X_test_imputed)\n",
    "\n",
    "    # Create X_cat which contains only the categorical variables\n",
    "    features_cat = [col for col in X.columns if X[col].dtype in [np.object]]\n",
    "    X_train_cat = X_train.loc[:, features_cat]\n",
    "    X_test_cat = X_test.loc[:, features_cat]\n",
    "\n",
    "\n",
    "    # Fill nans with a value indicating that that it is missing\n",
    "    X_train_cat.fillna(value=\"missing\", inplace=True)\n",
    "    X_test_cat.fillna(value=\"missing\", inplace=True)\n",
    "\n",
    "    # OneHotEncode Categorical variables\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    # OneHotEncode categorical variables\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Transform training and test sets\n",
    "    X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "    X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "    # Combine categorical and continuous features into the final dataframe\n",
    "    columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "    cat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\n",
    "    cat_test_df = pd.DataFrame(X_test_ohe.todense(), columns=columns)\n",
    "    \n",
    "    return X_train_all, X_test_all, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the training and test error to find optimal alpha values\n",
    "\n",
    "Earlier we tested two values of alpha to see how it effected our MSE and the value of our coefficients. We could continue to guess values of alpha for our Ridge or Lasso regression one at a time to see which values minimize our loss, or we can test a range of values and pick the alpha which minimizes our MSE. Here is an example of how we would do this:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train, y_test = preprocess(X, y)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "alphas = []\n",
    "\n",
    "for alpha in np.linspace(0, 200, num=75):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_all, y_train)\n",
    "    \n",
    "    train_preds = lasso.predict(X_train_all)\n",
    "    train_mse.append(mean_squared_error(y_train, train_preds))\n",
    "    \n",
    "    test_preds = lasso.predict(X_test_all)\n",
    "    test_mse.append(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "    alphas.append(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphasdf = pd.DataFrame(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>189.189189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>191.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>194.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>197.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.000000\n",
       "1     2.702703\n",
       "2     5.405405\n",
       "3     8.108108\n",
       "4    10.810811\n",
       "..         ...\n",
       "70  189.189189\n",
       "71  191.891892\n",
       "72  194.594595\n",
       "73  197.297297\n",
       "74  200.000000\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value: 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alphas, train_mse, label='Train')\n",
    "ax.plot(alphas, test_mse, label='Test')\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "# np.argmin() returns the index of the minimum value in a list\n",
    "optimal_alpha = alphas[np.argmin(test_mse)]\n",
    "\n",
    "# Add a vertical line where the test MSE is minimized\n",
    "ax.axvline(optimal_alpha, color='black', linestyle='--')\n",
    "ax.legend();\n",
    "\n",
    "print(f'Optimal Alpha Value: {int(optimal_alpha)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this graph of our training and test MSE against alpha. Try to explain to yourself why the shapes of the training and test curves are this way. Make sure to think about what alpha represents and how it relates to overfitting vs underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! You now know how to build Lasso and Ridge regression models, use them for feature selection and find an optimal value for $\\text{alpha}$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
